@page "/crawler"
@inject IConfiguration Configuration

@using System.Threading
@using Crawler3WebsocketClient
@using Microsoft.Extensions.Configuration
<h3>Crawler</h3>
<p style="font-size: smaller; overflow: auto; max-height: 200px">
    @foreach (var edge in _edges.Reverse()) {
        if (!string.IsNullOrWhiteSpace(edge)) {
            @edge
            <br/>
        }
    }
</p>
<p style="font-size: smaller">Edges: @_edgesCount, Nodes: @_nodesCount, Pending: @_pending, AvgProcessingTime: @($"{AvgPageLoadTime():0.00}")</p>
<input type="checkbox" @bind="_screenshots"/> Screenshots<br/>
<input type="number" min="0" max="6" @bind="_threads" /> Threads <br/>
<input type="url" @bind="_queue" /> Url <br/>
<input type="url" @bind="_filter" placeholder="@DefaultFilter" /> Filter
<button @onclick="Go">Go</button>
<button @onclick="Stop">Stop</button>
<h3>@_title</h3>
<p>@_url</p>
@if (!string.IsNullOrWhiteSpace(_img)) {
    <img style="width: 25%; height: auto" src="@_img" />
}
<p style="font-size: smaller">
    @foreach (var log in _logs) {
        if (!string.IsNullOrWhiteSpace(log)) {
            @log
            <br/>
        }
    }
</p>

@code {

    DateTimeOffset _begin;
    DateTimeOffset _lastUpdate;
    int _threads = 1;
    ulong _edgesCount;
    ulong _nodesCount;
    ulong _pending;
    readonly IList<string> _logs = new List<string>();
    string _img;
    string _title;
    string _filter;
    bool _screenshots;
    string DefaultFilter {
        get {
            if (!string.IsNullOrWhiteSpace(_queue)) return _queue + "[.*]";
            return null;
        }
    }
    string _url;
    readonly IList<string> _edges = new List<string>();
    CancellationTokenSource _cts;

    string _queue;

    Timer _timer;
    void TimerCb(object state) {
        InvokeAsync(StateHasChanged);
    }

    protected override Task OnInitializedAsync() {
        _timer = new Timer(TimerCb, null, 0, 2000);
        return Task.CompletedTask;
    }

    void Stop() {
        _cts?.Cancel(false);
    }

    double AvgPageLoadTime() => (_lastUpdate - _begin).TotalMilliseconds / _nodesCount;
    async Task Go()
    {
        try {
            _cts?.Cancel(false);
            _lastUpdate = _begin = DateTimeOffset.UtcNow;
            _cts = new CancellationTokenSource();
            _edges.Clear();
            _logs.Clear();
            _edgesCount = 0;
            _nodesCount = 0;


            var logger = new LambdaLogger(s => {
                _logs.Add(s);
                while (_logs.Count > 30) {
                    _logs.RemoveAt(0);
                }
            });
            using var client = new WebsocketJsonClient(new Uri(Configuration["CrawlerWebsocketUrl"]), logger);

            client.OnEdge += (e) => {
                var msg = string.IsNullOrWhiteSpace(e.Relation) ? $"{e.Parent} -> {e.Child}" : $"{e.Parent} -[{e.Relation}]> {e.Child}";
                _edges.Add(msg);
                _edgesCount++;
                while (_edges.Count > 500) {
                    _edges.RemoveAt(0);
                }
            };

            client.OnStatus += (s) => {
                _pending = s.PendingRequestCount;
                _nodesCount = s.HandledRequestCount;
            };

            client.OnEot += () => {
                _pending = 0;
                _lastUpdate = DateTimeOffset.UtcNow;
            };

            client.OnNode += (n) => {
                if (n.Screenshot != null && n.Screenshot.Length > 0) {
                    var encoded = Convert.ToBase64String(n.Screenshot);
                    _img = "data:image/png;base64," + encoded;
                }
                _title = n.Title;
                _url = n.Url;
                _nodesCount++;
                _lastUpdate = DateTimeOffset.UtcNow;
            };

            if (string.IsNullOrWhiteSpace(_filter)) _filter = null;

            await client.SendAsync(new CrawlerConfig()
            {
                CheckExternalLinks = false,
                FollowInternalLinks = true,
                TakeScreenshots = _screenshots,
                MaxConcurrency = _threads,
                MaxRequestsPerCrawl = 500,
                UrlFilter = _filter ?? DefaultFilter,
                RequestQueue = {
                    _queue
                }
            });
            var lastEx = await client.ReceiveAllAsync(cancellationToken: _cts.Token);
            if (lastEx != null) {
                _logs.Add("Client finished with Exception: " + lastEx);
            }
        }
        catch (Exception e) {
            _logs.Add(e.ToString());
        }
    }
}